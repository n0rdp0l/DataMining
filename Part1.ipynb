{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gabriele\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:17: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Mapping, defaultdict\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import numpy.ma as ma\n",
    "import random\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID  MovieID  Rating  Timestamp\n",
       "0       1     1193       5  978300760\n",
       "1       1      661       3  978302109\n",
       "2       1      914       3  978301968\n",
       "3       1     3408       4  978300275\n",
       "4       1     2355       5  978824291"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = pd.read_csv(\n",
    "   'ratings.dat',\n",
    "    sep = \"::\",\n",
    "    names = ['UserID', 'MovieID', 'Rating', 'Timestamp'],\n",
    "    encoding='latin-1',\n",
    "    engine='python',\n",
    ")\n",
    "\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Naive Methods\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 Global average rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The runtime of the algorithm is: 0.72\n",
      "The RMSE is: 1.1171\n",
      "The MAE is: 0.93386\n"
     ]
    }
   ],
   "source": [
    "## Global rating method\n",
    "start = time.time()\n",
    "random.seed(3)\n",
    "\n",
    "x = ratings.sample(frac = 1)\n",
    "X = np.array_split(x, 5) #Split dataset into 5 random subsets for Cross Validation\n",
    "\n",
    "rmses = []\n",
    "maes = []\n",
    "\n",
    "for i in range(5):\n",
    "    X_test = X[i] #Test set\n",
    "    X_train = pd.concat([X[j] for j in range(5) if j!=i]) #Combine 4 subsets for training set\n",
    "    average_score = np.mean(X_train['Rating']) #Compute average score of training set\n",
    "    reccomendations = np.array([average_score]*len(X_test)) #Predicted rating\n",
    "    rmse = np.sqrt(np.mean((reccomendations - X_test['Rating'])**2))\n",
    "    rmses += [rmse]\n",
    "    mae = np.mean(abs(reccomendations - X_test['Rating']))\n",
    "    maes += [mae]\n",
    "\n",
    "end = time.time()\n",
    "print('The runtime of the algorithm is: {}'.format(round(end - start,3)))\n",
    "print('The RMSE is: {}'.format(round(np.mean(rmses),5)))\n",
    "print('The MAE is: {}'.format(round(np.mean(maes),5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 User average rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The runtime of the algorithm is: 82.987\n",
      "The RMSE is: 1.03556\n",
      "The MAE is: 0.82909\n"
     ]
    }
   ],
   "source": [
    "## Per user rating\n",
    "start = time.time()\n",
    "random.seed(3)\n",
    "\n",
    "x = ratings.sample(frac = 1)\n",
    "X = np.array_split(x, 5) #Split dataset into 5 random subsets for Cross Validation\n",
    "\n",
    "rmses = []\n",
    "maes = []\n",
    "\n",
    "for i in range(5):\n",
    "    X_test = X[i] #Test set\n",
    "    X_train = pd.concat([X[j] for j in range(5) if j!=i]) #Combine 4 subsets for training set\n",
    "    reccomendations=[]\n",
    "    rat=dict.fromkeys(np.unique(X_train['UserID']))\n",
    "    \n",
    "    for user in np.unique(X_train['UserID']):\n",
    "        rat[user]=X_train.loc[X_train['UserID']==user]['Rating'].mean() #for each user in the training set compute the mean rating\n",
    "    for user in X_test['UserID']:\n",
    "        if user in rat:\n",
    "            reccomendations.append(rat[user]) #For each user in the test set, take its avreage rating from the training set\n",
    "        else:\n",
    "            reccomendations.append(np.mean(X_train['Rating'])) #If there is no occurence of the user in the training set, use global average\n",
    "    \n",
    "    rmse = np.sqrt(np.mean((reccomendations - X_test['Rating'])**2))\n",
    "    rmses += [rmse]\n",
    "    mae = np.mean(abs(reccomendations - X_test['Rating']))\n",
    "    maes += [mae]\n",
    "    \n",
    "end = time.time()\n",
    "print('The runtime of the algorithm is: {}'.format(round(end - start,3)))\n",
    "print('The RMSE is: {}'.format(round(np.mean(rmses),5)))\n",
    "print('The MAE is: {}'.format(round(np.mean(maes),5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3 Movie average rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Per item rating\n",
    "start = time.time()\n",
    "random.seed(3)\n",
    "\n",
    "x = ratings.sample(frac = 1)\n",
    "X = np.array_split(x, 5) #Split dataset into 5 random subsets for Cross Validation\n",
    "\n",
    "rmses = []\n",
    "maes = []\n",
    "\n",
    "for i in range(5):\n",
    "    X_test = X[i] #Test set\n",
    "    X_train = pd.concat([X[j] for j in range(5) if j!=i]) #Combine 4 subsets for training set\n",
    "    reccomendations=[]\n",
    "    rat=dict.fromkeys(np.unique(X_train['MovieID']))\n",
    "    \n",
    "    for movie in np.unique(X_train['MovieID']):\n",
    "        rat[movie]=X_train.loc[X_train['MovieID']==movie]['Rating'].mean() #for each movie in the training set compute the mean rating\n",
    "    for movie in X_test['MovieID']:\n",
    "        if movie in rat:\n",
    "            reccomendations.append(rat[movie]) #For each movie in the test set, take its avreage rating from the training set\n",
    "        else:\n",
    "            reccomendations.append(np.mean(X_train['Rating'])) #If there is no occurence of the movie in the training set, use global average\n",
    "    \n",
    "    rmse = np.sqrt(np.mean((reccomendations - X_test['Rating'])**2))\n",
    "    rmses += [rmse]\n",
    "    mae = np.mean(abs(reccomendations - X_test['Rating']))\n",
    "    maes += [mae]\n",
    "    \n",
    "end = time.time()\n",
    "print('The runtime of the algorithm is: {}'.format(round(end - start,3)))\n",
    "print('The RMSE is: {}'.format(round(np.mean(rmses),5)))\n",
    "print('The MAE is: {}'.format(round(np.mean(maes),5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.4/5 Linear regression with and without coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Linear regression\n",
    "\n",
    "start = time.time()\n",
    "random.seed(3)\n",
    "\n",
    "x = ratings.sample(frac = 1)\n",
    "X = np.array_split(x, 5) #Split dataset into 5 random subsets for Cross Validation\n",
    "simrmses = [] #simple linear rigression = no intercept\n",
    "simmaes = []\n",
    "rmses = [] #linear regression with intercept\n",
    "maes = []\n",
    "\n",
    "for i in range(5):\n",
    "    X_test = X[i] #Test set\n",
    "    X_train = pd.concat([X[j] for j in range(5) if j!=i]) #Combine 4 subsets for training set\n",
    "    \n",
    "    train=X_train.pivot(index='MovieID', columns='UserID', values='Rating') #Training set into matrix form\n",
    "    colavg=train.mean() #User average\n",
    "    rowavg=train.mean(axis=1) #Movie average\n",
    "    average_score = np.mean(X_train['Rating']) #Average score (in case missing values for test set)\n",
    "    \n",
    "    indexes=train[train.notnull()].stack().index #Indexes of all the non-NA values\n",
    "    lr=[]\n",
    "    for k in indexes:\n",
    "        lr.append((rowavg[k[0]],colavg[k[1]],train.loc[k[0],k[1]])) #Create a list of (Movie_avg, User_avg, Rating)\n",
    "        \n",
    "    df = pd.DataFrame(lr, columns = ['x1', 'x2','y'])\n",
    "    simplereg=LinearRegression(fit_intercept=False).fit(df.iloc[:,0:2],df.iloc[:,2]) #Linear regression without intercept\n",
    "    reg=LinearRegression().fit(df.iloc[:,0:2],df.iloc[:,2]) #Linear regression with intercept\n",
    "    \n",
    "    for i in range(ratings['MovieID'].max()):\n",
    "        if (i not in rowavg):\n",
    "            rowavg[i]=average_score #If in the test set there is no movie average, use global average\n",
    "    for i in range(ratings['UserID'].max()):\n",
    "        if (i not in colavg):\n",
    "            colavg[i]=average_score #If in the test set there is no user average, use global average\n",
    "            \n",
    "    #Recommendation computed with linear regression without intercept\n",
    "    simplereccom = simplereg.coef_[0]*rowavg[X_test['MovieID']].reset_index()[0]+simplereg.coef_[1]*colavg[X_test['UserID']].reset_index()[0]\n",
    "    #Recommendation computed with linear regression with intercept\n",
    "    reccom = reg.intercept_+reg.coef_[0]*rowavg[X_test['MovieID']].reset_index()[0]+reg.coef_[1]*colavg[X_test['UserID']].reset_index()[0]\n",
    "    \n",
    "    #Values higher than 5 are rounded to 5 and values smaller than 1 are rounded to 1\n",
    "    for i in range(len(simplereccom)-1):\n",
    "        if (simplereccom[i]>5):\n",
    "            simplereccom[i]=5\n",
    "        elif (simplereccom[i]<1):\n",
    "            simplereccom[i]=1\n",
    "    \n",
    "    for i in range(len(reccom)-1):\n",
    "        if (reccom[i]>5):\n",
    "            reccom[i]=5\n",
    "        elif (reccom[i]<1):\n",
    "            reccom[i]=1\n",
    "        \n",
    "    #RMSE and MAE for linear regression without intercept\n",
    "    simrmse = np.sqrt(np.mean((simplereccom - X_test['Rating'].reset_index()['Rating'])**2))\n",
    "    simrmses += [simrmse]\n",
    "    simmae = np.mean(abs(simplereccom - X_test['Rating'].reset_index()['Rating']))\n",
    "    simmaes += [simmae]\n",
    "    \n",
    "    #RMSE and MAE for linear regression with intercept\n",
    "    rmse = np.sqrt(np.mean((reccom - X_test['Rating'].reset_index()['Rating'])**2))\n",
    "    rmses += [rmse]\n",
    "    mae = np.mean(abs(reccom - X_test['Rating'].reset_index()['Rating']))\n",
    "    maes += [mae]\n",
    "    \n",
    "end = time.time()\n",
    "print('The runtime of the algorithm is: {}'.format(round(end - start,3)))\n",
    "print('The RMSE of the linear regression without intercept is: {}'.format(round(np.mean(simrmses),5)))\n",
    "print('The MAE of the linear regression without intercept is: {}'.format(round(np.mean(simmaes),5)))\n",
    "print('The RMSE of the linear regression with intercept is: {}'.format(round(np.mean(rmses),5)))\n",
    "print('The MAE of the linear regression with intercept is: {}'.format(round(np.mean(maes),5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 UV Matrix Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes: To increase our chances of finding the global minimum, we need to pick many dif- ferent starting points, that is, different choices of the initial matrices U and V . However, there is never a guarantee that our best local minimum will be the global minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Matrix_Decomposition:\n",
    "    def __init__(self, matrix, dimensions = 5, iterations = 1):\n",
    "        self.matrix = matrix\n",
    "        self.n = self.matrix.shape[0]\n",
    "        self.m = self.matrix.shape[1]\n",
    "        self.d = dimensions\n",
    "        self.normalized = self.matrix - np.nanmean(self.matrix,axis=1, keepdims=True)\n",
    "        self.normalized = self.matrix - np.nanmean(self.matrix,axis=0, keepdims=True)\n",
    "        self.U = np.random.rand(self.n,self.d) + np.sqrt(np.nanmean(self.matrix)/self.d)\n",
    "        self.V = np.random.rand(self.d,self.m) + np.sqrt(np.nanmean(self.matrix)/self.d)\n",
    "        self.iter = iterations\n",
    "        self.transformed_UV = np.dot(self.U, self.V)+np.nanmean(self.matrix,axis=0, keepdims=True)+np.nanmean(self.matrix,axis=1, keepdims=True)\n",
    "            \n",
    "    def rmse(self):\n",
    "        UV = np.dot(self.U,self.V)\n",
    "        error = np.nanmean((self.normalized - UV)**2)\n",
    "        return error\n",
    "\n",
    "\n",
    "    def UV(self):\n",
    "        start = time.time()\n",
    "        err = [self.rmse()]\n",
    "        for i in range(self.iter):\n",
    "            # decompose user matrix\n",
    "            for r in range(0,self.n):\n",
    "                for s in range(0,self.d):\n",
    "                    m = np.array(self.normalized[r,:])\n",
    "                    v = np.array(self.V[s,:])\n",
    "                    u = np.array(self.U[r,:])\n",
    "                    index_no_s = np.array(range(self.d)) != s\n",
    "                    self.U[r,s]=np.nansum(v*(m-np.dot(u[index_no_s],self.V[index_no_s,:])))/np.sum(v**2)\n",
    "            \n",
    "            # decompose item matrix\n",
    "            for s in range(0,self.m):\n",
    "                for r in range(0,self.d):\n",
    "                    m = np.array(self.normalized[:,s])\n",
    "                    u = np.array(self.U[:,r])\n",
    "                    v = np.array(self.V[:,s])\n",
    "                    index_no_r = np.array(range(self.d)) != r\n",
    "                    self.V[r,s]=np.nansum(u * (m-np.dot(self.U[:,index_no_r],v[index_no_r])))/np.sum(u**2)\n",
    "                    \n",
    "            if err[i] - self.rmse() < 0.000001 and i > self.iter/2:\n",
    "                break\n",
    "            \n",
    "            else:\n",
    "                print('Iteration: ' + str(i+1) + ', Error: ' + str(self.rmse_new()))\n",
    "                err.append(self.rmse_new())\n",
    "\n",
    "        end = time.time()\n",
    "        print('The runtime of the algorithm is: {}'.format(round(end - start,3)))\n",
    "\n",
    "        return self.U, self.V, err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing runtime for different number of iterations\n",
    "random.seed(3)\n",
    "models = dict()\n",
    "for i in range (5):\n",
    "    models[i] = Matrix_Decomposition(M, iterations = i, dimensions = 5)\n",
    "\n",
    "for i in range (5):\n",
    "    print(\"Iteration: \" + str(i))\n",
    "    models[i].UV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing error behaviour for different dimensions\n",
    "random.seed(3)\n",
    "models = dict()\n",
    "for i in range (10):\n",
    "    models[i] = Matrix_Decomposition(M, iterations = 5, dimensions = i)\n",
    "\n",
    "for i in range (10):\n",
    "    print(\"Dimension: \" + str(i+1))\n",
    "    models[i].UV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Prediction of ratings\n",
    "random.seed(3)\n",
    "start = time.time()\n",
    "\n",
    "x = ratings.sample(frac = 1)\n",
    "X = np.array_split(x, 5)\n",
    "\n",
    "rmses = []\n",
    "maes = []\n",
    "\n",
    "for i in range(5):\n",
    "    # Find train and test utility matrices\n",
    "    X_test = X[i]\n",
    "    X_train = pd.concat([X[j] for j in range(5) if j!=i])\n",
    "    Y_test = X_test.copy()\n",
    "    Y_train = X_train.copy()\n",
    "    Y_train[['Rating']] = np.nan\n",
    "    X_test = pd.concat([X_test,Y_train])\n",
    "    Y_test[['Rating']] = np.nan\n",
    "    X_train = pd.concat([X_train, Y_test])\n",
    "    \n",
    "    # Perform prediction\n",
    "    Utility_DF = X_train.pivot(index = 'UserID', columns ='MovieID', values = 'Rating')\n",
    "    Utility_test = X_test.pivot(index = 'UserID', columns ='MovieID', values = 'Rating')\n",
    "    \n",
    "    M = Utility_DF.to_numpy()\n",
    "    M_test = Utility_test.to_numpy()\n",
    "    model_matrix = Matrix_Decomposition(M, iterations = 90)\n",
    "    uv = model_matrix.UV()\n",
    "    r=np.dot(model_matrix.U, model_matrix.V)+np.nanmean(M,axis=0, keepdims=True)+np.nanmean(M,axis=1, keepdims=True)\n",
    "    rmse = np.sqrt(np.nanmean((r - M_test)**2))\n",
    "    rmses += [rmse]\n",
    "    mae = np.nanmean(abs(r - M_test))\n",
    "    maes += [mae]\n",
    "    \n",
    "end = time.time()\n",
    "print('The runtime of the algorithm is: {}'.format(round(end - start,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r=np.dot(model_matrix.U, model_matrix.V)+np.nanmean(M,axis=0, keepdims=True)+np.nanmean(M,axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.sqrt(np.nanmean((M-r)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Matrix Factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We firstly show the code without Cross Validation, this is the one we have then used for the second part of the code. \n",
    "In the second block, Cross validation is applied to Matrix factorization too, unfortunately this code too long to run so we have preferred to use the former for the second part. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MATRIX FACTORIZATION WITHOUT CROSS VALIDATION\n",
    "\n",
    "start = time.time()\n",
    "random.seed(3)\n",
    "\n",
    "# Parameters reported on Mymedialite website\n",
    "learn_rate=0.005\n",
    "reg=0.05\n",
    "num_factors=10\n",
    "num_iter=75\n",
    "\n",
    "x = ratings.pivot(index='MovieID', columns='UserID', values='Rating') \n",
    "M=np.random.rand(x.shape[0],num_factors) #Initialize the weights in M randomly (the number of rows is the number of movies, the number of columns is 10: num_factors)\n",
    "M=pd.DataFrame(M, index=x.index) \n",
    "U=np.random.rand(num_factors,x.shape[1]) #Initialize the weights in U randomly (the number of columns is the number of users, the number of rows is 10: num_factors)\n",
    "U=pd.DataFrame(U, columns=x.columns)\n",
    "\n",
    "indexes=x[x.notnull()].stack().index\n",
    "iterat=1\n",
    "rmse=100\n",
    "newrmse=99\n",
    "\n",
    "while (iterat < num_iter and newrmse-rmse < 0.01 ): #Matrix Factorization algorithm\n",
    "    print('iteration: ' + str(iterat))\n",
    "    iterat += 1\n",
    "    for k in indexes: #iterate over each known element of X\n",
    "        movie = M.loc[k[0],]\n",
    "        user = U.loc[:,k[1]]\n",
    "        x_hat = np.dot(movie,user) #Predicted rating\n",
    "        error = x.loc[k[0],k[1]] - x_hat #Compute the training error\n",
    "        M.loc[k[0],] = movie + learn_rate * (2*error*user - reg*movie) #Update the corresponding row of M based on the equation from the paper\n",
    "        U.loc[:,k[1]] = user + learn_rate * (2*error*movie - reg*user) #Update the corresponding columns of U based on the equation from the paper\n",
    "            \n",
    "    factoriz=pd.DataFrame(np.matmul(M, U), index=x.index, columns= x.columns)\n",
    "    rmse=newrmse\n",
    "    newrmse=np.sqrt(((factoriz-x)**2).mean().mean()) #Compute the new RMSE, and check whether it has decreased before next loop\n",
    "            \n",
    "mae = abs(factoriz-x).mean().mean()\n",
    "\n",
    "end = time.time()\n",
    "print('The runtime of the algorithm is: {}'.format(round(end - start,3)))\n",
    "print('The RMSE of the linear regression without intercept is: {}'.format(round(newrmse,5)))\n",
    "print('The MAE of the linear regression without intercept is: {}'.format(round(mae,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MATRIX FACTORIZATION WITH CROSS VALIDATION\n",
    "\n",
    "start = time.time()\n",
    "random.seed(3)\n",
    "\n",
    "x = ratings.sample(frac = 1) #Split dataset into 5 random subsets for Cross Validation\n",
    "X = np.array_split(x, 5)\n",
    "\n",
    "# Parameters reported on Mymedialite website\n",
    "learn_rate=0.005\n",
    "reg=0.05\n",
    "num_factors=10\n",
    "num_iter=75\n",
    "\n",
    "rmses = []\n",
    "maes = []\n",
    "\n",
    "for i in range(5):\n",
    "    print(i)\n",
    "    X_test = X[i]\n",
    "    X_train = pd.concat([X[j] for j in range(5) if j!=i])\n",
    "    train=X_train.pivot(index='MovieID', columns='UserID', values='Rating')\n",
    "    \n",
    "    M=np.random.rand(train.shape[0],num_factors) #Initialize the weights in M randomly (the number of rows is the number of movies, the number of columns is 10: num_factors)\n",
    "    M=pd.DataFrame(M, index=train.index)\n",
    "    U=np.random.rand(num_factors,train.shape[1]) #Initialize the weights in U randomly (the number of columns is the number of users, the number of rows is 10: num_factors)\n",
    "    U=pd.DataFrame(U, columns=train.columns)\n",
    "    \n",
    "    indexes=train[train.notnull()].stack().index\n",
    "    iterat=1\n",
    "    rmse=100\n",
    "    newrmse=99\n",
    "    \n",
    "    while (iterat < num_iter and newrmse-rmse < 0.01 ): #Matrix Factorization algorithm\n",
    "        iterat+=1\n",
    "        for k in indexes: #iterate over each known element of X\n",
    "            movie = M.loc[k[0],]\n",
    "            user = U.loc[:,k[1]]\n",
    "            x_hat = np.dot(movie,user) #Predicted rating\n",
    "            error = train.loc[k[0],k[1]] - x_hat #Compute the training error\n",
    "            M.loc[k[0],] = movie + learn_rate * (2*error*user - reg*movie) #Update the corresponding row of M based on the equation from the paper\n",
    "            U.loc[:,k[1]] = user + learn_rate * (2*error*movie - reg*user) #Update the corresponding columns of U based on the equation from the paper\n",
    "            \n",
    "        factoriz=pd.DataFrame(np.matmul(M, U), index=train.index, columns= train.columns)\n",
    "        rmse=newrmse\n",
    "        newrmse=np.sqrt(np.mean((factoriz[factoriz.columns & test.columns]-test)**2))\n",
    "            \n",
    "    #rmse = np.sqrt(np.mean((np.matmul(M, U)-train)**2))\n",
    "    rmses += [newrmse]\n",
    "    mae = np.mean(abs(factoriz[factoriz.columns & test.columns]-test))\n",
    "    maes += [mae]\n",
    "    \n",
    "end = time.time()\n",
    "print('The runtime of the algorithm is: {}'.format(round(end - start,3)))\n",
    "print('The RMSE is: {}'.format(round(np.mean(rmses),5)))\n",
    "print('The MAE is: {}'.format(round(np.mean(maes),5)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "16a0f2890d1def7920885bcd7e8b768c0e805614be8083e52d1bdef4cb90280f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
